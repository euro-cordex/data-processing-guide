<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Model Run &#8212; REMO Documentation and User Guide 0 documentation</title>
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.12.4.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.4.1/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-inverse navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html"><span><img src="_static/REMO_logo.png"></span>
          REMO</a>
        <span class="navbar-text navbar-version pull-left"><b>2</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="http://remo-rcm.de">Homepage</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="syntax-examples.html">1. Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="syntax-examples.html#headings">1.1. Headings</a></li>
<li class="toctree-l2"><a class="reference internal" href="syntax-examples.html#code">1.2. Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="syntax-examples.html#admonitions">1.3. Admonitions</a></li>
<li class="toctree-l2"><a class="reference internal" href="syntax-examples.html#footnotes">1.4. Footnotes</a></li>
<li class="toctree-l2"><a class="reference internal" href="syntax-examples.html#icons">1.5. Icons</a></li>
<li class="toctree-l2"><a class="reference internal" href="syntax-examples.html#tables">1.6. Tables</a></li>
<li class="toctree-l2"><a class="reference internal" href="syntax-examples.html#code-documentation">1.7. Code Documentation</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Model Run</a><ul>
<li><a class="reference internal" href="#compilation">Compilation</a><ul>
<li><a class="reference internal" href="#compilation-with-netcdf-support">Compilation with NETCDF support</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-input-namelist-file">The INPUT Namelist File</a></li>
<li><a class="reference internal" href="#the-job-control-script">The Job Control Script</a><ul>
<li><a class="reference internal" href="#configuration">Configuration</a></li>
<li><a class="reference internal" href="#execution-of-the-remo-model">Execution of the REMO model</a></li>
<li><a class="reference internal" href="#postprocessing">Postprocessing</a><ul>
<li><a class="reference internal" href="#the-python-mrun-control-script-suite">The Python MRUN Control Script Suite</a></li>
<li><a class="reference internal" href="#autosubmit">Autosubmit</a></li>
</ul>
</li>
<li><a class="reference internal" href="#prerequisites-for-autosubmit-on-mistral">Prerequisites for autosubmit on MISTRAL</a></li>
<li><a class="reference internal" href="#running-a-remo-experiment-with-autosubmit">Running a REMO experiment with autosubmit</a><ul>
<li><a class="reference internal" href="#postprocessing-during-model-run">Postprocessing during Model Run</a></li>
</ul>
</li>
<li><a class="reference internal" href="#pressure-interpolation">Pressure Interpolation</a></li>
<li><a class="reference internal" href="#archiving">Archiving</a></li>
</ul>
</li>
<li><a class="reference internal" href="#model-spin-up">Model Spin Up</a><ul>
<li><a class="reference internal" href="#replacing-surface-and-soil-data-in-a-forcing-file">Replacing Surface and Soil Data in a Forcing File</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/model_run.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="model-run">
<h1>Model Run<a class="headerlink" href="#model-run" title="Permalink to this headline">¶</a></h1>
<div class="line-block">
<div class="line">In this chapter, we describe the basics steps of compiling and running
the REMO model after all input data has been created successfully.
Usually, a model run should be organized on a monthly basis. This
means that the entire period of the experiment is not computed during
one model run but rather successively by consecutive model runs that
span a period of one month. The model is configured to write a restart
file at the end of each month and is restarted at beginning of the
next month. By this, the entire timeframe of the experiment can be
divided into relatively small computational tasks (typically of a few
minutes to hours of wallclock time) that can be handled by most job
scheduling system. Trying to run the model in one go would most
probably exceed the allowed wallclock limit of most supercomputing
systems. Furthermore, if the model run fails, the user does not loose
to much data but can simply restart the model at the current month.
Most REMO runscripts (Section [sec:runscript]) follow this idea and
are based on the idea of creating REMO namelists on a monthly basis.
Furthermore, the runscript should also take care of creating an
appropriate directory structure for the model run and handle output
data.</div>
<div class="line">Furthermore, since REMO most often is used for downscaling
experiments, soil temperatures and some other model variables might
not be in an equilibrium with the model atmosphere because of the
higher resolution in comparison to the original driving data.
Therefore, an initial <em>spin up</em> of some soil variables and a following
restart of the model might be neccessary (Section [sec:spinup])</div>
</div>
<div class="section" id="compilation">
<h2>Compilation<a class="headerlink" href="#compilation" title="Permalink to this headline">¶</a></h2>
<div class="line-block">
<div class="line">REMO is written in Fortran and when you have obtained the code, the
directory structure of the model should more or less look like this:</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">build</span>  <span class="c1"># makefiles</span>
<span class="o">/</span><span class="n">CBS</span>    <span class="c1"># module source code</span>
<span class="o">/</span><span class="n">CODE</span>   <span class="c1"># source code</span>
<span class="o">/</span><span class="n">jobs</span>   <span class="c1"># job scripts</span>
<span class="o">/</span><span class="n">OFS</span>    <span class="c1"># object directory for compiling</span>
</pre></div>
</div>
<p>You will have to compile the source code yourself on the machine you
will execute the run. Go to the /build directory in which you will find
a Makefile to create a machine specific makefile. There is also another
subdirectory you don’t have to care about right now. Go to the /build
directory and get the available compilation options by typing:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> build
make
</pre></div>
</div>
<p>which should result in a similar output to this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>usage: &lt;make clean&gt; &lt;make clean_all&gt; &lt;make mistral&gt; &lt;make blizzard&gt; &lt;make tornado&gt; &lt;make ubuntu_laptop&gt; &lt;make meteo&gt; &lt;make bull&gt; &lt;make juropa&gt;
</pre></div>
</div>
<p>The only purpose of the makefile here is to create a machine specific
makefile from some files in the subdirectory /makefiles. There are some
predefined makefile configurations for different machines but, in
general, they only differ in which fortran compiler or mpi
implementation is used. So if you are working on an ubuntu system, try
typing:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make ubuntu_laptop
</pre></div>
</div>
<p>which means nothing else than using the gnu fortran compiler <em>gfortran</em>
with the open mpi implementation which both are usually available on the
ubuntu distribution. However, if this fails, you can adapt the makefile
template for a linux machine to your configuration by editing the file
Makefile_ubuntu_laptop.txt in /makefiles/templates. If you are lucky
to have a valid account on the MISTRAL supercomputer of the DKRZ in
Hamburg, you can simply type:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make mistral
</pre></div>
</div>
<p>which should work if your environment matches the DKRZ recommendations.
Again, this only means that remo is compiled on an intel machine using
the intel fortran compiler (ifort) with a bullxmpi implementation of
mpif90. This means that you should have loaded the following modules,
e.g, by adding this line your shell or bash profile:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use the default versions of Intel compiler and Bullx MPI with Mellanox MXM and FCA tools</span>
module load intel mxm fca bullxmpi_mlx
</pre></div>
</div>
<p>We highly recommend that you have a look at the MISTRAL documentation on
the homepage of DKRZ. If compilation was successful, you can find the
machine specific makefile in the <code class="docutils literal notranslate"><span class="pre">makefiles</span></code> subdirectory in the
<code class="docutils literal notranslate"><span class="pre">build</span></code> directory. If you have to change any compiler options, do it
in this file, e.g., <code class="docutils literal notranslate"><span class="pre">Makefile_mistral</span></code> and not in the template itself
which is located in a further subdirectory called
<code class="docutils literal notranslate"><span class="pre">makefile/templates</span></code>.</p>
<div class="section" id="compilation-with-netcdf-support">
<h3>Compilation with NETCDF support<a class="headerlink" href="#compilation-with-netcdf-support" title="Permalink to this headline">¶</a></h3>
<p>The compilation of REMO with NETCDF support requires to link the netcdf
library. The netcdf library needs to be installed on the system which on
an HPC system usually is the case. Configuration details for the netcdf
libary can be accessed using the <code class="docutils literal notranslate"><span class="pre">nc-config</span></code> tool. However, for most
Linux desktop computers and for the MISTRAL, the Makefiles templates
contain the required pathes and libraries for compiling REMO with netcdf
support. Managing the call of in and ouput routine in REMO is done using
the a preprocessor macro defined by <code class="docutils literal notranslate"><span class="pre">NCMODE</span></code>. To use the NETCDF
support, you have to change the Makefile in the makefiles subdirectory
in the build directory, e.g., the Makefile_mistral. Open the Makefile
and uncomment the lines that define the NETCDF variable (for compiling)
and the NCLIBS variable (for linking). For the Mistral, these lines
should be something like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">NCMODE</span>    <span class="o">=</span>  <span class="n">NETCDF_IO</span>
<span class="n">NCFLAGS</span>   <span class="o">=</span> <span class="o">-</span><span class="n">D</span><span class="p">{</span><span class="n">NCMODE</span><span class="p">}</span> <span class="o">-</span><span class="n">I</span><span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">netcdf</span><span class="o">/</span><span class="n">netcdf_fortran</span><span class="o">-</span><span class="mf">4.4</span><span class="o">.</span><span class="mi">2</span><span class="o">-</span><span class="n">intel14</span><span class="o">/</span><span class="n">include</span>
<span class="n">NCLIBS</span>    <span class="o">=</span> <span class="o">-</span><span class="n">L</span><span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">netcdf</span><span class="o">/</span><span class="n">netcdf_fortran</span><span class="o">-</span><span class="mf">4.4</span><span class="o">.</span><span class="mi">2</span><span class="o">-</span><span class="n">intel14</span><span class="o">/</span><span class="n">lib</span> <span class="o">-</span><span class="n">lnetcdff</span> \
            <span class="o">-</span><span class="n">Wl</span><span class="p">,</span><span class="o">-</span><span class="n">rpath</span><span class="p">,</span><span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">netcdf</span><span class="o">/</span><span class="n">netcdf_fortran</span><span class="o">-</span><span class="mf">4.4</span><span class="o">.</span><span class="mi">2</span><span class="o">-</span><span class="n">intel14</span><span class="o">/</span><span class="n">lib</span> \
            <span class="o">-</span><span class="n">L</span><span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">netcdf</span><span class="o">/</span><span class="n">netcdf_c</span><span class="o">-</span><span class="mf">4.3</span><span class="o">.</span><span class="mi">2</span><span class="o">-</span><span class="n">gcc48</span><span class="o">/</span><span class="n">lib</span> \
            <span class="o">-</span><span class="n">Wl</span><span class="p">,</span><span class="o">-</span><span class="n">rpath</span><span class="p">,</span><span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">netcdf</span><span class="o">/</span><span class="n">netcdf_c</span><span class="o">-</span><span class="mf">4.3</span><span class="o">.</span><span class="mi">2</span><span class="o">-</span><span class="n">gcc48</span><span class="o">/</span><span class="n">lib</span> \
            <span class="o">-</span><span class="n">L</span><span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">hdf5</span><span class="o">/</span><span class="n">hdf5</span><span class="o">-</span><span class="mf">1.8</span><span class="o">.</span><span class="mi">14</span><span class="o">-</span><span class="n">threadsafe</span><span class="o">-</span><span class="n">gcc48</span><span class="o">/</span><span class="n">lib</span> \
            <span class="o">-</span><span class="n">Wl</span><span class="p">,</span><span class="o">-</span><span class="n">rpath</span><span class="p">,</span><span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">hdf5</span><span class="o">/</span><span class="n">hdf5</span><span class="o">-</span><span class="mf">1.8</span><span class="o">.</span><span class="mi">14</span><span class="o">-</span><span class="n">threadsafe</span><span class="o">-</span><span class="n">gcc48</span><span class="o">/</span><span class="n">lib</span> \
            <span class="o">-</span><span class="n">L</span><span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">sys</span><span class="o">/</span><span class="n">libaec</span><span class="o">-</span><span class="mf">0.3</span><span class="o">.</span><span class="mi">2</span><span class="o">-</span><span class="n">gcc48</span><span class="o">/</span><span class="n">lib</span> \
            <span class="o">-</span><span class="n">Wl</span><span class="p">,</span><span class="o">-</span><span class="n">rpath</span><span class="p">,</span><span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">sys</span><span class="o">/</span><span class="n">libaec</span><span class="o">-</span><span class="mf">0.3</span><span class="o">.</span><span class="mi">2</span><span class="o">-</span><span class="n">gcc48</span><span class="o">/</span><span class="n">lib</span> \
            <span class="o">-</span><span class="n">lnetcdf</span> <span class="o">-</span><span class="n">lhdf5_hl</span> <span class="o">-</span><span class="n">lhdf5</span> <span class="o">-</span><span class="n">lsz</span> <span class="o">-</span><span class="n">lcurl</span> <span class="o">-</span><span class="n">lz</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">NCMODE</span></code> variable will define a flag for a macro called that is
interpreted by the preprocessor. The <code class="docutils literal notranslate"><span class="pre">NCMODE</span></code> has three options:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">NCMODE</span>    <span class="o">=</span>  <span class="n">NETCDF_IO</span>    <span class="k">for</span> <span class="n">Netcd</span> <span class="n">Input</span> <span class="ow">and</span> <span class="n">Output</span>
<span class="n">NCMODE</span>    <span class="o">=</span>  <span class="n">NETCDF_IN</span>    <span class="k">for</span> <span class="n">Netcdf</span> <span class="n">Input</span> <span class="ow">and</span> <span class="n">IEG</span> <span class="n">Output</span>
<span class="n">NCMODE</span>    <span class="o">=</span>  <span class="n">NETCDF_OUT</span>   <span class="k">for</span> <span class="n">IEG</span> <span class="n">Input</span> <span class="ow">and</span> <span class="n">Netcdf</span> <span class="n">Output</span>
</pre></div>
</div>
<p>Note, that in the case you choose IEG input and Netcdf Output, the
restart file will be written still in IEG format so that the model can
be restarted with IEG input. Make sure, that you have activated the
preprocessor, e.g, the <code class="docutils literal notranslate"><span class="pre">-fpp</span></code> flag for the Intel compiler or the
<code class="docutils literal notranslate"><span class="pre">-xf77-cpp-input</span></code> for the GNU compiler (it’s actually c preprocessor
syntax). But this should be already prepared in the appropriate Makefile
templates. Furthermore, you have to uncomment the lines, that include
the new dependencies of the REMO netcdf module source code (in the CODE
directory). These are further down in the Makefile, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">include</span> <span class="o">../</span><span class="n">CODE</span><span class="o">/</span><span class="n">makefile</span><span class="o">.</span><span class="n">netcdf</span>
</pre></div>
</div>
<p>We have separated the netcdf dependencies and used preprocessor macros
because this is the most flexible way to handle the different
implementations of the IO module. This is also useful because REMO can
still be compiled without relying on the external fortran netcdf
library.</p>
<p>Now, you can compile REMO the usual way by typing, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">mistral</span>
</pre></div>
</div>
<p>Remeber, you have to be in the build directory for this to work. If you
did already compile REMO before without NETCDF support, you have to
recompile. To make sure, first clean up and compile then, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">make</span> <span class="n">clean_all</span>
<span class="n">make</span> <span class="n">mistral</span>
</pre></div>
</div>
<p>That sould compile REMO with NETCDF support.</p>
</div>
</div>
<div class="section" id="the-input-namelist-file">
<h2>The INPUT Namelist File<a class="headerlink" href="#the-input-namelist-file" title="Permalink to this headline">¶</a></h2>
<p>The REMO model requires a Namelist File called <code class="docutils literal notranslate"><span class="pre">INPUT</span></code> at runtime.
Some of the most important Namelists and Parameters are listed in
Table [tab:namelist_overview]. A full description of all parameters
can be found in Appendix [cha:remo_namelist]. However, most
parameters are set by default during the REMO run but the parameters
in Table [tab:namelist_overview] need special attention since they
are domain specific and dependet on the setup of the experiment during
preprocessing. The most important settings are the following:</p>
<div class="topic">
<p class="topic-title first"><code class="docutils literal notranslate"><span class="pre">PARCTL</span></code></p>
<p>Here you have to choose how the REMO domain is
decomposed for parallel computation. <code class="docutils literal notranslate"><span class="pre">NPROCXM</span></code> and <code class="docutils literal notranslate"><span class="pre">NPROCYM</span></code> define the
number of subdivions in x- and y-direction of the domain. Usually, an
evenly distribution of cells per processor is most efficient but
should not be less than 400 cells (e.g., 20x20 cells) because
otherwise the communication overhead might dominate the model run.</p>
</div>
<div class="topic">
<p class="topic-title first"><code class="docutils literal notranslate"><span class="pre">EMGRID</span></code></p>
<p>Here you have to adjust the parameters of your
model domain (as in the preprocessor namelist, see above), i.e., lat
and lon of the lower left corner in the rotated system (<code class="docutils literal notranslate"><span class="pre">PHILU</span></code>,``RLALU``),
lat and lon of the rotated north pole (<code class="docutils literal notranslate"><span class="pre">POLPHI</span></code>, <code class="docutils literal notranslate"><span class="pre">POLLAM</span></code>) and the
resolution in x- and y-direction in degrees (<code class="docutils literal notranslate"><span class="pre">DLAM</span></code>, <code class="docutils literal notranslate"><span class="pre">DPHI</span></code>).</p>
</div>
<div class="topic">
<p class="topic-title first"><code class="docutils literal notranslate"><span class="pre">RUNCTL</span></code></p>
<p>Adjust the time of model initialisation (very
first time step, <code class="docutils literal notranslate"><span class="pre">YADAT</span></code>), the time step in seconds (<code class="docutils literal notranslate"><span class="pre">DT</span></code>) and the
temporal resolution of the driving fields (<code class="docutils literal notranslate"><span class="pre">NHDR</span></code>) which is in almost
all cases 6 hours. Furthermore, the switches <code class="docutils literal notranslate"><span class="pre">LMOMON</span></code> (FALSE if real
month are to be computed, <code class="docutils literal notranslate"><span class="pre">TRUE</span></code> if the forcing only has 30 days per
month), <code class="docutils literal notranslate"><span class="pre">LQWR</span></code> (<code class="docutils literal notranslate"><span class="pre">TRUE</span></code> if forcing contains liquid water, <code class="docutils literal notranslate"><span class="pre">FALSE</span></code> if not) and
<code class="docutils literal notranslate"><span class="pre">LSCEN</span></code> (<code class="docutils literal notranslate"><span class="pre">TRUE</span></code> if time-dependent greenhouse gas concentrations are to be
used, FALSE for constant greenhouse gas concentrations) have to be
set.</p>
</div>
<div class="topic">
<p class="topic-title first"><code class="docutils literal notranslate"><span class="pre">PHYCTL</span></code></p>
<p>Adjust the switches <code class="docutils literal notranslate"><span class="pre">LVEG</span></code> (<code class="docutils literal notranslate"><span class="pre">TRUE</span></code> if monthly varying
vegetation fields are to be used, <code class="docutils literal notranslate"><span class="pre">FALSE</span></code> if not), <code class="docutils literal notranslate"><span class="pre">LSICED</span></code> (<code class="docutils literal notranslate"><span class="pre">TRUE</span></code> if the
forcing contains sea ice concentrations, FALSE if not and if the sea
ice concentration should be diagnosed from <code class="docutils literal notranslate"><span class="pre">SST</span></code>) and <code class="docutils literal notranslate"><span class="pre">LAEROZ</span></code> (<code class="docutils literal notranslate"><span class="pre">TRUE</span></code> if
time dependent aerosol and ozone background concentrations are to be
used, <code class="docutils literal notranslate"><span class="pre">FALSE</span></code> if constant background concentrations are used).</p>
</div>
<div class="topic">
<p class="topic-title first"><code class="docutils literal notranslate"><span class="pre">DATEN</span></code></p>
<p>Adjust the names of the three vegetation files
(annual cycle of three parameters, see abobe; <code class="docutils literal notranslate"><span class="pre">YBDNAM</span></code>), the name of the
file containing the time-dependent greenhouse gas concentrations
(<code class="docutils literal notranslate"><span class="pre">YGDNAM</span></code>) and, if applicable, the filenames for the time-dependent
ozone, aerosol and sulfate concentrations (<code class="docutils literal notranslate"><span class="pre">YO3DNAM</span></code>, <code class="docutils literal notranslate"><span class="pre">YSADNAM</span></code>, <code class="docutils literal notranslate"><span class="pre">YSNDNAM</span></code>).</p>
</div>
<table border="1" class="docutils">
<colgroup>
<col width="11%" />
<col width="12%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Namelist</th>
<th class="head">Parameter</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>PARCTL</td>
<td>NPROCXM</td>
<td>Number of preocessors in x-direction (longitude)</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>NPROCYM</td>
<td>Number of preocessors in y-direction (latitude)</td>
</tr>
<tr class="row-even"><td>EMGRID</td>
<td>MOIE</td>
<td>Number of grid boxes in x-direction (longitude)</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>MOJE</td>
<td>Number of grid boxes in y-direction (latitude)</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>MOKE</td>
<td>Number of layers</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>PHILU</td>
<td>Latitude of lower left grid box center</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>RLALU</td>
<td>Longitude of lower left grid box center</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>POLPHI</td>
<td>Latitude of the rotated North Pole</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>POLLAM</td>
<td>Longitude of the rotated North Pole</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>DLAM</td>
<td>Meshsize in x-direction (degree)</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>DPHI</td>
<td>Meshsize in y-direction (degree)</td>
</tr>
<tr class="row-odd"><td>RUNCTL</td>
<td>NHANF</td>
<td>Starting hour relative to start date</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>NHENDE</td>
<td>Ending hour relative to start date</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YADAT</td>
<td>Start date</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>DT</td>
<td>time step in seconds</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>NHDR</td>
<td>Temporal resolution of drving data (usually 6 hours)</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>LQWR</td>
<td>TRUE if forcinf files contains liquid water content</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>LMOMON</td>
<td>TRUE if forcing files have 30 days per month</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>LSCEN</td>
<td>Switch for time-dependent greenhouse gas concentration</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>LMOMIT</td>
<td>TRUE if monthly means, max and mins should be written</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>DLAND</td>
<td>Cloud height over land that has to be reached at least before a cloud may rain</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>DNOPRC</td>
<td>Cloud height over ocean that has to be reached at least before a cloud may rain</td>
</tr>
<tr class="row-even"><td>PHYCTL</td>
<td>LPHY</td>
<td>TRUE if REMO physics should computed</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>HDRAD</td>
<td>Time intervall for radiation calculations</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>LVEG</td>
<td>TRUE if monthly varying vegetation fields are used</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>LSICED</td>
<td>TRUE if forcing file contains sea ice concentration</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>LAEROZ</td>
<td>TRUE if time dependent aerosol and ozone concentrations are used</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>L5LAY</td>
<td>TRUE if 5 soil layer model should be used</td>
</tr>
<tr class="row-even"><td>DATEN</td>
<td>YADEN</td>
<td>Experiment number of the input data</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YRDEN</td>
<td>Experiment number of the input data (YADEN=YRDEN)</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>YEDEN</td>
<td>Experiment number of the ’xe’ files</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YFDEN</td>
<td>Experiment number of the ’xf’ files</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>YTDEN</td>
<td>Experiment number of the ’xt’ files</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YUSERA</td>
<td>User number of the input data</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>YUSERE</td>
<td>User number of the output files</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YADCAT</td>
<td>Path to the input files (a-files)</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>YRDCAT</td>
<td>Path to the input files</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YEDCAT</td>
<td>Path to the ’xe’ files</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>YFDCAT</td>
<td>Path to the ’xf’ files</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YMDCAT</td>
<td>Path to the ’xm’ files</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>YTDCAT</td>
<td>Path to the ’xt’ files</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YNDCAT</td>
<td>Path to the ’xn’ files</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>YMVARN</td>
<td>Name of fields that go into timeseries files (e-file,m-file)</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YNVARN</td>
<td>Name of fields that go daily mean,min,max files (n-file)</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>YTVARN</td>
<td>Name of fields that go into a t-file</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YBDCAT</td>
<td>Path to the files below</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>YBDNAM</td>
<td>List of files</td>
</tr>
<tr class="row-odd"><td>&#160;</td>
<td>YGDCAT</td>
<td>Path to GHG-file</td>
</tr>
<tr class="row-even"><td>&#160;</td>
<td>YGDNAM</td>
<td>GHG-filename</td>
</tr>
</tbody>
</table>
<p>Table: Important Namelist Parameters</p>
<p>You might want to have another look at the run script for the test setup
that was describe in Chapter [cha:quickstart] for a better understanding
of how the Namelist looks like and what kind of numbers go into it.</p>
<div class="line-block">
<div class="line">If the REMO experiment should be handled on a monthly basis, some of
the parameters in the Namelists will change from month to month (e.g.
start and end hour ot the simulation) and some will stay the same
(e.g. data pathes, parallelization, etc.). Therefore, it is a good
idea to use a job control script (e.g., the one from Chapter
[cha:quickstart]) that will handle the creation of the NAMELIST
dynamically and automatically submits a job script for each month
successively.</div>
<div class="line">You could either use the jobscript from Chapter [cha:quickstart] as a
basis and create your own job control script from that. But depending
on the environment you work in, it might be a good idea to adapt
existing job scripts that are already working in the existing
environment and, e.g., fullfill certain data directory conventions.</div>
</div>
</div>
<div class="section" id="the-job-control-script">
<h2>The Job Control Script<a class="headerlink" href="#the-job-control-script" title="Permalink to this headline">¶</a></h2>
<p>The job control script for a model production run, that spans a
timeframe of several years and decades and produces a considerable
amount of output data, should take care of these tasks:</p>
<ul class="simple">
<li>prepare an appropriate directory structure for the model run</li>
<li>copy and extract input data to the model run directory</li>
<li>create an INPUT file and set NAMELIST parameters</li>
<li>execute the model run</li>
<li>postprocess and backup the output model data</li>
</ul>
<p>All of this taks should be handled on a monthly basis by the jobscript.
The script should basically contain a loop over all month that should be
computed, and for each month, it submits a job script to the scheduling
system. Fortunaltey, a number of job control scripts already exist that
can be, in principle, adapted to any HPC system.</p>
<div class="line-block">
<div class="line">A suite of jobscripts that has been used for most of the REMO model
runs so far is available in the <code class="docutils literal notranslate"><span class="pre">./jobs</span></code> subdirectory of the model.
These scripts are especially useful for REMO runs that are conducted
at the DKRZ on MISTRAL because they make use of the tape archive (HPSS
filesystem) from where it gets forcing data and where it stores output
data of the model run. It actually consists of a bash script called
<code class="docutils literal notranslate"><span class="pre">run_remo.ksh</span></code> that requires some python scripts and templates to
run. The job script <code class="docutils literal notranslate"><span class="pre">run_remo.ksh</span></code> itself is supposed to be a batch
script that can be submitted to the job scheduling system of the
MISTRAL. The script itself checks if an appropriate directory
structure for the output data existst on the <code class="docutils literal notranslate"><span class="pre">WORK</span></code> partition (where
the output data is copied after finishing one month of model run) and
if a directory for the model run itself is available on the
<code class="docutils literal notranslate"><span class="pre">SCRATCH</span></code> partition (where data is written during the model run
itself). This is usually the best approach of handling output data
from REMO: Writing the model output data to a <code class="docutils literal notranslate"><span class="pre">SCRATCH</span></code> parition
where the user usually has a lot of disk space (which is cleaned
regularly) and afterwards, copying the results to the <code class="docutils literal notranslate"><span class="pre">WORK</span></code>
parition where it can be stored until the end of the experiment (the
last month of simulation time) and the be archived.</div>
<div class="line">The directory structure of files in the job control script more or
less should look like this:</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">config_druint</span><span class="o">.</span><span class="n">txt</span>         <span class="c1"># config file for pressure interpolation</span>
<span class="n">log</span><span class="o">/</span>                      <span class="c1"># directory for logfiles</span>
<span class="n">NEXP</span>                      <span class="c1"># experiment number</span>
<span class="n">NMON</span>                      <span class="c1"># number of current month in current year</span>
<span class="n">NSA</span>                       <span class="c1"># starting hour of current run</span>
<span class="n">NYEAR</span>                     <span class="c1"># current year</span>
<span class="n">pressure_interpolation</span><span class="o">.</span><span class="n">py</span> <span class="c1"># script for running the pressure interpolation</span>
<span class="n">putscript</span><span class="o">.</span><span class="n">py</span>              <span class="c1"># script for tarring and archiving output data</span>
<span class="n">run_remo</span><span class="o">.</span><span class="n">ksh</span>              <span class="c1"># the main job script (batch script)</span>
<span class="n">scripts</span><span class="o">/</span>                  <span class="c1"># directory for job scripts</span>
<span class="n">templates</span><span class="o">/</span>                <span class="c1"># directory for job script templates</span>
</pre></div>
</div>
<div class="section" id="configuration">
<h3>Configuration<a class="headerlink" href="#configuration" title="Permalink to this headline">¶</a></h3>
<p>The main job script that is submitted to the job scheduling system is
<code class="docutils literal notranslate"><span class="pre">run_remo.ksh</span></code>. In the header of the script, a number of variables are
defined which control pathes and parameters for the REMO run. The first
part deals with the job scheduling system and, for the SLURM job
scheduler on MISTRAL, it looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#SBATCH --job-name=056112           # Specify job name</span>
<span class="c1">#SBATCH --partition=compute         # Specify partition name for job execution</span>
<span class="c1">#SBATCH --nodes=3                   # Specify number of nodes</span>
<span class="c1">#SBATCH --ntasks-per-node=24        # Specify max. number of tasks per node</span>
<span class="c1">#SBATCH --time=01:00:00             # Set a limit on the total run time</span>
<span class="c1">#SBATCH --account=ch0636            # Charge resources on this project account</span>
<span class="c1">#SBATCH --output ./log/056112_%j.o  # output file</span>
<span class="c1">#SBATCH --error ./log/056112_%j.o   # error file</span>
</pre></div>
</div>
<div class="line-block">
<div class="line">The entries here are examples for an MPI parallelized job. On the
homepage of the DKRZ, you can find many more examples for job scripts.
However, if you run REMO on a different machine, you would have to
adapt the header to the job scheduling system available. You can also
ignore the job scheduling header and execute the job script directly
if you want to run it on a desktop computer without job scheduling.</div>
<div class="line">Afterwards, you can define some parameters concerning your experiment,
e.g.,</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>PFADJOB=                    # working directory where the job control script is
EXP=`cat ${PFADJOB}/NEXP`   # experiment number of current experiment
M=  `cat ${PFADJOB}/NMON`   # current month
Y=  `cat ${PFADJOB}/NYEAR`  # current year
KSA=`cat ${PFADJOB}/NSA`    # current start hour
USER=056                    # user number of current experiment
BUSER=056                   # user number of boundary data
BEXP=112                    # experiment number of boundary data
YSTART=1948                 # first year
YSTOP=2101                  # first year  that is not calculated
MSTOP=01                    # first month that is not calculated
PROJID=ch0636               # project number (for the pathes)
PROJIDRUN=ch0636            # account number for the MISTRAL
DT=240                      # time step of the simulation
</pre></div>
</div>
<div class="line-block">
<div class="line">The experiment number, current month, current year and current start
hour (<code class="docutils literal notranslate"><span class="pre">NEXP</span></code>, <code class="docutils literal notranslate"><span class="pre">NMON</span></code>, <code class="docutils literal notranslate"><span class="pre">NYEAR</span></code>, <code class="docutils literal notranslate"><span class="pre">NSA</span></code>) are read from the
corresponding plain ASCII files in the main directory of the job
script suite (called <code class="docutils literal notranslate"><span class="pre">PFADJOB</span></code>). The reason for this is, that these
small files will be updated by the jobscript itself when the run for
one month is finished. In the end, the jobscript will actually submit
itself to start the model run for the next month and read in the
updated files for the next month. This has the advantage that no loop
over month is neccessary and no control script has to run in a bash
shell for the duration of the complete experiment (which could easily
be several weeks of wallclock time).</div>
<div class="line">You also have to put in your user number <code class="docutils literal notranslate"><span class="pre">USER</span></code> which is maily
needed to setup the directory structure and because it is part of file
naming conventions when the script postprocesses the model output. The
same holds for the user number <code class="docutils literal notranslate"><span class="pre">BUSER</span></code> and experiment number
<code class="docutils literal notranslate"><span class="pre">BEXP</span></code> of boundary data. This information is needed for the script
to know where to look for boundary data eithner on the <code class="docutils literal notranslate"><span class="pre">SCRATCH</span></code>
partition or in the tape archive.</div>
<div class="line">Afterwards, you can define the first and last year of the simulation
as well as the last month. The project number <code class="docutils literal notranslate"><span class="pre">PROJID</span></code> is als used
for setting up the directory structure and for searching of boundary
data in the archive if neccessary. <code class="docutils literal notranslate"><span class="pre">PROJIDRUN</span></code> is the account number
that is used for the scheduling system. Finally, you can define a time
step for the simulation <code class="docutils literal notranslate"><span class="pre">DT</span></code>.</div>
<div class="line">These parameters are used to define some path variables:</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#
# Dateipfade festlegen:
#
WRKSHR=${SCRATCH}                  # Scratch directory
PFL=${PFADJOB}/remo2009_mpi/libs   # Remo executable
PFADCTRL=/pool/data/remo           # input files, such as albcycle.f
PFADFRC=${WRKSHR}/bound_${BUSER}${BEXP} # where forcing is copied/locally stored
DIRARC=/hpss/arch/${PROJID}/${USERID}/exp${BUSER}${BEXP}  # Boundary-Data
PFADRES=/work/${PROJID}/g300046/remo_results_${USER}${EXP}  #  Results
DIR=${WRKSHR}/tmp_${USER}${EXP}    # Temporary working directory
DIRWS=$DIR                         # where namelist and restartfiles are written
</pre></div>
</div>
<p>where most of the variables are defined automaticall using a certain
convention for names and pathes within GERICS at DKRZ. For example,
files concerning the files for the mean annucal cycle is located on the
MISTRAL in <code class="docutils literal notranslate"><span class="pre">/pool/data/remo</span></code>. Further down in the <code class="docutils literal notranslate"><span class="pre">run_remo.ksh</span></code>
script you can see how the <code class="docutils literal notranslate"><span class="pre">INPUT</span></code> file is created:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cat</span> <span class="o">&gt;</span> <span class="n">INPUT</span> <span class="o">&lt;&lt;</span> <span class="n">EOF</span>
<span class="o">&amp;</span><span class="n">PARCTL</span>
 <span class="n">NPROCXM</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
 <span class="n">NPROCYM</span><span class="o">=</span><span class="mi">8</span>
<span class="o">/</span>
<span class="o">&amp;</span><span class="n">EMGRID</span>
 <span class="n">MOIE</span><span class="o">=</span><span class="mi">129</span><span class="p">,</span>
 <span class="n">MOJE</span><span class="o">=</span><span class="mi">121</span><span class="p">,</span>
<span class="o">...</span>
 <span class="n">YBDNAM</span><span class="o">=</span><span class="s1">&#39;vgryear_cordex044.srv&#39;</span><span class="p">,</span><span class="s1">&#39;vltyear_cordex044.srv&#39;</span><span class="p">,</span><span class="s1">&#39;albyear_cordex044.srv&#39;</span><span class="p">,</span>
 <span class="n">YGDCAT</span><span class="o">=</span><span class="s1">&#39;\$</span><span class="si">{PFADCTRL}</span><span class="s1">&#39;</span><span class="p">,</span>
 <span class="n">YGDNAM</span><span class="o">=</span><span class="s1">&#39;GHG_rcp26_1850-2101.txt&#39;</span>
<span class="o">/</span>
<span class="n">EOF</span>
</pre></div>
</div>
<p>The script creates the namelists in a file called <code class="docutils literal notranslate"><span class="pre">INPUT</span></code> using the
<code class="docutils literal notranslate"><span class="pre">cat</span></code> command. You can see that some parameters are set directly, e.g,
in the <code class="docutils literal notranslate"><span class="pre">EMGRID</span></code> namelist while others are derived from variables in
the bash script, e.g., in the <code class="docutils literal notranslate"><span class="pre">DATEN</span></code> namelist. These parameters are
partly defined by the bash script variables that where defined above or
depend on the current month of the model run, e.g., <code class="docutils literal notranslate"><span class="pre">NHANF</span></code> and
<code class="docutils literal notranslate"><span class="pre">NHENDE</span></code>. The <code class="docutils literal notranslate"><span class="pre">INPUT</span></code> file is then created automatically in the
temporary working directory (the script variable <code class="docutils literal notranslate"><span class="pre">DIR</span></code>) and updated
for each month. If you want to change some of the parameters that are
set directly, you can do it here. However, you should not change the
parameters that are set dynamically and which are used for data in and
output since these depend on the parameters that where set above.</p>
</div>
<div class="section" id="execution-of-the-remo-model">
<h3>Execution of the REMO model<a class="headerlink" href="#execution-of-the-remo-model" title="Permalink to this headline">¶</a></h3>
<p>After the preparation of input data and the creation of the <code class="docutils literal notranslate"><span class="pre">INPUT</span></code>
file, the REMO model can finally be executed by using the appropriate
implementation of <code class="docutils literal notranslate"><span class="pre">mpirun</span></code> or any other tool that manages parallel
execution of an MPI program for the job scheduler at hand. For <code class="docutils literal notranslate"><span class="pre">SLRUM</span></code>
on MISTRAL, we use <code class="docutils literal notranslate"><span class="pre">srun</span></code> which can is executed in the run script
similar to this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>srun -l --cpu_bind=verbose,cores ${PFL}/rremo &lt; INPUT
</pre></div>
</div>
</div>
<div class="section" id="postprocessing">
<h3>Postprocessing<a class="headerlink" href="#postprocessing" title="Permalink to this headline">¶</a></h3>
<p>Further down in the <code class="docutils literal notranslate"><span class="pre">run_remo.ksh</span></code> file, you can see how a
postprocessing script is created in the <code class="docutils literal notranslate"><span class="pre">./scripts</span></code> subdirectory,
e.g.,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#
# ******************  Write and call postprocessing script ******************
#
sed -e &#39;s%^#BQSC%%&#39; &gt; ./scripts/fpost_${USER}${EXP}_${Y}${M} &lt;&lt;EOF
#!/bin/ksh
###############################################################################
#
#SBATCH --job-name=fpost_${USER}${EXP}_${Y}${M}   # Specify job name
#SBATCH --partition=shared         # Specify partition name for job execution
#SBATCH --nodes=1                  # Specify number of nodes
#SBATCH --ntasks-per-node=1        # Specify max. number of tasks
#SBATCH --time=01:00:00            # Set a limit on the total run time
#SBATCH --account=ch0636           # Charge resources on this project account
#SBATCH --output=./log/fpost_${USER}${EXP}_${Y}${M}.log
#SBATCH --error=./log/fpost_${USER}${EXP}_${Y}${M}.log
###############################################################################
#

...

#
# **** Job fuer Folgemonat submitten:
#
cd \${PFADJOB}
sbatch run_remo_mistral.sh
#

....

print &quot; |- Post processing completed    |\n |-------------------------------|\n&quot;
set -x
date
#-----------------------------------------------------------------------------
exit 0
#-----------------------------------------------------------------------------
EOF
#
# ******  Launch postprocessing script
#
sbatch ./scripts/fpost_${USER}${EXP}_${Y}\${M}
#
echo &quot;Remo postprocessing was sent to the queue.&quot;
</pre></div>
</div>
<div class="line-block">
<div class="line">Here are two important things to notice. First, the <code class="docutils literal notranslate"><span class="pre">run_script.ksh</span></code>
script creates the postprocessing script <code class="docutils literal notranslate"><span class="pre">fpost_$USER$EXP_$Y$M</span></code> for
the current month separately in the <code class="docutils literal notranslate"><span class="pre">./scripts</span></code> subdirectory and
submits it to the job scheduler afterwards (using the <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>)
command. That is why the postprocessing script also contains another
header for the job scheduler but using a different partition (e.g.,
the <em>shared</em> partition for serial jobs). After the <code class="docutils literal notranslate"><span class="pre">run_script.ksh</span></code>
script has submitted the postprocessing script, it finishes and the
the postprocessing script is executed by the job scheduler. The main
job of the postprocessing script is then to tar all output data into a
small number of files and copy them to the <code class="docutils literal notranslate"><span class="pre">WORK</span></code> partiton.
Afterwards, the postprocessing script also submits the
<code class="docutils literal notranslate"><span class="pre">run_remo.ksh</span></code> which then is ready to start again for the following
month by reading in the updated configuration files <code class="docutils literal notranslate"><span class="pre">NMON</span></code> (current
month), <code class="docutils literal notranslate"><span class="pre">NYEAR</span></code> (current year) and <code class="docutils literal notranslate"><span class="pre">NSA</span></code> (current starting hour).</div>
<div class="line">In summary, the approach of the shell script suite is to submit the
jobscript <code class="docutils literal notranslate"><span class="pre">run_remo.ksh</span></code> which reads in the configuration for the
current month, executes the model run, and submits a postprocessing
script. After the postprocessing has been finished, the postprocessing
scripts resubmits the jobscript <code class="docutils literal notranslate"><span class="pre">run_remo.ksh</span></code> with the
configuration for the next month and the whole workflow starts again.</div>
<div class="line">When the configuration has been done successfully, the job script can
be submitted using</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sbatch</span> <span class="n">run_remo</span><span class="o">.</span><span class="n">ksh</span>
</pre></div>
</div>
<div class="section" id="the-python-mrun-control-script-suite">
<h4>The Python MRUN Control Script Suite<a class="headerlink" href="#the-python-mrun-control-script-suite" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="autosubmit">
<h4>Autosubmit<a class="headerlink" href="#autosubmit" title="Permalink to this headline">¶</a></h4>
<p>Autosubmit is a python based job control infrastructure maintained by
the Barcelona Supercomputing Center (BSC). It allows to manage
dependencies in a hierarchy of job scripts across several computers.
Especially the management of large ensemble simulations can be easily
automated using autosubmit, but it also provides convenience when
performing single transient runs. To learn the basics of autosubmit
please refer to the official autosubmit documentation
(<a class="reference external" href="https://autosubmit.readthedocs.io/en/latest/">https://autosubmit.readthedocs.io/en/latest/</a>). At GERICS we set up an
internal server with a central installation of autosubmit called SUBMIT
(IP: 136.172.63.15) which is set up to perform simulations on MISTRAL.
If you plan to use autosubmit elsewhere and run on MISTRAL, some
adjustments have to be made due to insufficient support of the SLURM
batch system used on MISTRAL in the official release of autsubmit.
<strong>TODO: Add patch to autosubmit folder?</strong> In the following, the
procedure to use autosubmit from our SUBMIT server to run jobs on
MISTRAL is explained.</p>
</div>
</div>
<div class="section" id="prerequisites-for-autosubmit-on-mistral">
<h3>Prerequisites for autosubmit on MISTRAL<a class="headerlink" href="#prerequisites-for-autosubmit-on-mistral" title="Permalink to this headline">¶</a></h3>
<p>In order to make autosubmit run properly, some settings have to be
done/adjusted. In short the following steps have to taken:</p>
<ol class="arabic simple">
<li>set up <code class="docutils literal notranslate"><span class="pre">ssh</span></code> autologin to MISTRAL from SUBMIT</li>
<li>install PyRemo on MISTRAL</li>
<li>add PyRemo path to <code class="docutils literal notranslate"><span class="pre">$PYTHONPATH</span></code> environment variable</li>
<li>load the <code class="docutils literal notranslate"><span class="pre">module</span></code> environment for non-interactive shells</li>
<li>load <code class="docutils literal notranslate"><span class="pre">cdo</span></code> and <code class="docutils literal notranslate"><span class="pre">pftp</span></code> modules for non-interactive shells</li>
</ol>
<p>The first step is straightforward and is equivalent to the set up on
other machines with <code class="docutils literal notranslate"><span class="pre">ssh</span></code> password-less login. A simple google search
will provide a number of guides on how to do that. The SUBMIT server has
<code class="docutils literal notranslate"><span class="pre">keychain</span></code> installed for easy passphrase protected <code class="docutils literal notranslate"><span class="pre">ssh</span></code> autologin.
The second and third step is installing PyRemo on MISTRAl and adding it
to the python environment. If you have not done it yet, please refer to
the PyRemo documentation on how to do it. The third and fourth steps are
essential to make python scripts running that are part of the autosubmit
set up coming with REMO. Depending on your shell, the following needs be
included in your <code class="docutils literal notranslate"><span class="pre">.profile</span></code> or <code class="docutils literal notranslate"><span class="pre">.cshrc</span></code> respectively:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># in bash or ksh script</span>
<span class="n">source</span> <span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">profile</span><span class="o">.</span><span class="n">mistral</span>

<span class="c1"># in tcsh or csh script</span>
<span class="n">source</span> <span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">csh</span><span class="o">.</span><span class="n">mistral</span>
</pre></div>
</div>
<p>to make the <code class="docutils literal notranslate"><span class="pre">module</span></code> command available in all by autosubmit submitted
jobs. Currently two modules have to be loaded in same script which are
<code class="docutils literal notranslate"><span class="pre">pftp</span></code> and <code class="docutils literal notranslate"><span class="pre">cdo</span></code>. The complete section in a <code class="docutils literal notranslate"><span class="pre">.profile</span></code> script for
<code class="docutils literal notranslate"><span class="pre">bash</span></code> would look like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">source</span> <span class="o">/</span><span class="n">sw</span><span class="o">/</span><span class="n">rhel6</span><span class="o">-</span><span class="n">x64</span><span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">profile</span><span class="o">.</span><span class="n">mistral</span>

<span class="n">module</span> <span class="n">load</span> <span class="n">pftp</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">cdo</span>
</pre></div>
</div>
<p>All these settings could also be added to each individual autosubmit
script, but would make executing python scripts impossible.</p>
</div>
<div class="section" id="running-a-remo-experiment-with-autosubmit">
<h3>Running a REMO experiment with autosubmit<a class="headerlink" href="#running-a-remo-experiment-with-autosubmit" title="Permalink to this headline">¶</a></h3>
<p>In general, autosubmit gives the freedom to define all sorts of
dependencies between jobs running on various computer platforms. The
following example describes an autosubmit workflow that allows to
downscale one or multiple members of a global model experiment with the
same amount of REMO simulations. In this example many scripts described
above and below from model compilation and NAMELIST creation to data
archiving are implemented in the autosubmit workflow. Depending on the
parent script more or less adjustments where undertaken to make best use
of the autosubmit capabilities (e.g., build-in calendar).</p>
<p>First of all, after setting up autosubmit an autosubmit experiment needs
to be defined. This can be achieved by typing, e.g.,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">autosubmit</span> <span class="n">expid</span> <span class="o">--</span><span class="n">HPC</span> <span class="n">DKRZ</span> <span class="o">-</span><span class="n">d</span> <span class="s2">&quot;REMO test&quot;</span>
</pre></div>
</div>
<p>on the command line of the SUBMIT server. The option <code class="docutils literal notranslate"><span class="pre">–HPC</span> <span class="pre">DKRZ</span></code> will
tell autosubmit that the DKRZ platform will be used as default for our
experiment. After <code class="docutils literal notranslate"><span class="pre">-d</span></code> you can put a short description of the
experiment. Running the command will create a new directory (e.g.,
<code class="docutils literal notranslate"><span class="pre">a001</span></code>) in your autosubmit root folder, which will contain several
sub-directories. Change to the sub-directory with the configuration
files (e.g., <code class="docutils literal notranslate"><span class="pre">a001/conf</span></code>). It will contain at least four files:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">autosubmit_a001</span><span class="o">.</span><span class="n">conf</span>  <span class="n">expdef_a001</span><span class="o">.</span><span class="n">conf</span>  <span class="n">jobs_a001</span><span class="o">.</span><span class="n">conf</span>  <span class="n">platforms_a001</span><span class="o">.</span><span class="n">conf</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">platforms_a001.conf</span></code> holds the configuration for the computer you
are running your experiment on. For MISTRAL it will look like the
following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example platform with all options specified</span>

<span class="c1">## Platform name</span>
<span class="p">[</span><span class="n">DKRZ</span><span class="p">]</span>
<span class="c1">## Queue type. Options: PBS, SGE, PS, LSF, ecaccess, SLURM</span>
<span class="n">TYPE</span> <span class="o">=</span> <span class="n">SLURM</span>
<span class="c1">## Version of queue manager to use. Needed only in PBS (options: 10, 11, 12) and ecaccess (options: pbs, loadleveler)</span>
<span class="c1"># VERSION =</span>
<span class="c1">## Hostname of the HPC</span>
<span class="n">HOST</span> <span class="o">=</span> <span class="n">mistral</span><span class="o">.</span><span class="n">dkrz</span><span class="o">.</span><span class="n">de</span>
<span class="c1">## Project for the machine scheduler</span>
<span class="n">PROJECT</span> <span class="o">=</span> <span class="n">ch0636</span>
<span class="c1">## Budget account for the machine scheduler. If omitted, takes the value defined in PROJECT</span>
<span class="n">BUDGET</span> <span class="o">=</span> <span class="n">ch0636</span>
<span class="c1">## Option to add project name to host. This is required for some HPCs</span>
<span class="c1"># ADD_PROJECT_TO_HOST = False</span>
<span class="c1">## User for the machine scheduler</span>
<span class="n">USER</span> <span class="o">=</span> <span class="n">m212075</span>
<span class="c1">## Path to the scratch directory for the machine</span>
<span class="n">SCRATCH_DIR</span> <span class="o">=</span> <span class="o">/</span><span class="n">scratch</span><span class="o">/</span><span class="n">m</span><span class="o">/</span><span class="n">m212075</span>
<span class="c1">## If true, autosubmit test command can use this queue as a main queue. Defaults to false</span>
<span class="c1"># TEST_SUITE = False</span>
<span class="c1">## If given, autosubmit will add jobs to the given queue</span>
<span class="n">QUEUE</span> <span class="o">=</span> <span class="n">compute</span>
<span class="c1">## If specified, autosubmit will run jobs with only one processor in the specified platform.</span>
<span class="c1"># SERIAL_PLATFORM = SERIAL_PLATFORM_NAME</span>
<span class="c1">## If specified, autosubmit will run jobs with only one processor in the specified queue.</span>
<span class="c1">## Autosubmit will ignore this configuration if SERIAL_PLATFORM is provided</span>
<span class="n">SERIAL_QUEUE</span> <span class="o">=</span> <span class="n">shared</span>
<span class="c1">## Default number of processors per node to be used in jobs</span>
<span class="n">PROCESSORS_PER_NODE</span> <span class="o">=</span> <span class="mi">6</span>
<span class="c1">## Scratch free space requirements for the platform in percentage (%). If not specified, it won&#39;t be defined on the template.</span>
<span class="c1"># SCRATCH_FREE_SPACE = 10</span>
<span class="c1">## Default Maximum number of jobs to be waiting in any platform queue</span>
<span class="c1">## Default = 3</span>
<span class="c1"># MAX_WAITING_JOBS = 3</span>
<span class="c1">## Default maximum number of jobs to be running at the same time at any platform</span>
<span class="c1">## Default = 6</span>
<span class="c1"># TOTAL_JOBS = 6</span>
</pre></div>
</div>
<p>Make sure that the correct <code class="docutils literal notranslate"><span class="pre">PROJECT</span></code>, <code class="docutils literal notranslate"><span class="pre">BUDGET</span></code> and <code class="docutils literal notranslate"><span class="pre">USER</span></code> are set.
In <code class="docutils literal notranslate"><span class="pre">autosubmit_a001.conf</span></code> the configuration of autosubmit itself is
located. The default setting should be fine for now. The same holds for
the <code class="docutils literal notranslate"><span class="pre">jobs_a001.conf</span></code> file, which will be replaced later. The
configuration file that needs the most work is <code class="docutils literal notranslate"><span class="pre">expdef_a001.conf</span></code>.
Like all autosubmit configuration files, it is set up as unix
configuration file with sections embraced by brackets ([]) and options
with a name on the left and content on the right hand side of an equal
sign. First, find the <code class="docutils literal notranslate"><span class="pre">[experiment]</span></code> section and fill in the
information on your experiment. As an example we will run a ten year
test simulation with REMO in 0.44° resolution over Europe starting in
2000. To be consistent with the standard REMO output we will run each
month separately. The corresponding <code class="docutils literal notranslate"><span class="pre">[experiment]</span></code> section will look
like the following</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">experiment</span><span class="p">]</span>
<span class="c1"># Supply the list of start dates. Available formats: YYYYMMDD YYYYMMDDhh YYYYMMDDhhmm</span>
<span class="c1"># You can also use an abbreviated syntax for multiple dates with common parts: 200001[01 15] &lt;=&gt; 20000101 20000115</span>
<span class="c1"># 200001[01-04] &lt;=&gt; 20000101 20000102 20000103 20000104</span>
<span class="c1"># DATELIST = 19600101 19650101 19700101</span>
<span class="c1"># DATELIST = 1960[0101 0201 0301]</span>
<span class="c1"># DATELIST = 19[60-65]</span>
<span class="n">DATELIST</span> <span class="o">=</span> <span class="mi">20000101</span>
<span class="c1"># Supply the list of members. Format fcX</span>
<span class="c1"># You can also use an abreviated syntax for multiple members: fc[0 1 2] &lt;=&gt; fc0 fc1 fc2</span>
<span class="c1"># fc[0-2] &lt;=&gt; fc0 fc1 fc2</span>
<span class="c1"># MEMBERS = fc0 fc1 fc2 fc3 fc4</span>
<span class="c1"># MEMBERS = fc[0-4]</span>
<span class="n">MEMBERS</span> <span class="o">=</span> <span class="n">eur044</span>
<span class="c1"># Chunk size unit. STRING = hour, day, month, year</span>
<span class="n">CHUNKSIZEUNIT</span> <span class="o">=</span> <span class="n">month</span>
<span class="c1"># Chunk size. NUMERIC = 4, 6, 12</span>
<span class="n">CHUNKSIZE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># Total number of chunks in experiment. NUMERIC = 30, 15, 10</span>
<span class="n">NUMCHUNKS</span> <span class="o">=</span> <span class="mi">120</span>
<span class="c1"># Calendar used. LIST: standard, noleap</span>
<span class="n">CALENDAR</span> <span class="o">=</span> <span class="n">standard</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">DATELIST</span></code> is the start date, <code class="docutils literal notranslate"><span class="pre">MEMBERS</span></code> is the name of the
simulation, which in case of REMO has an additional meaning explained
later, <code class="docutils literal notranslate"><span class="pre">CHUNKSIZEUNIT,</span> <span class="pre">CHUNKSIZE</span></code> and <code class="docutils literal notranslate"><span class="pre">NUMCHUNKS</span></code> are the settings
for chunk and simulation length.</p>
<p>Next, we have to tell autosubmit in what kind of repository the REMO
code is stored and in which location. This will be configured by the
following two sections of the <code class="docutils literal notranslate"><span class="pre">expdef_a001.conf</span></code> file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">project</span><span class="p">]</span>
<span class="c1"># Select project type. STRING = git, svn, local, none</span>
<span class="c1"># If PROJECT_TYPE is set to none, Autosubmit self-contained dummy templates will be used</span>
<span class="n">PROJECT_TYPE</span> <span class="o">=</span> <span class="n">git</span>
<span class="c1"># Destination folder name for project. type = STRING, default = leave empty,</span>
<span class="n">PROJECT_DESTINATION</span> <span class="o">=</span>

<span class="c1"># If PROJECT_TYPE is not git, no need to change</span>
<span class="p">[</span><span class="n">git</span><span class="p">]</span>
<span class="c1"># Repository URL  STRING = &#39;https://github.com/torvalds/linux.git&#39;</span>
<span class="n">PROJECT_ORIGIN</span> <span class="o">=</span> <span class="s1">&#39;https://Kevin.Sieck@git.gerics.de/REMO/REMO_MPI.git&#39;</span>
<span class="c1"># Select branch or tag, STRING, default = &#39;master&#39;, help = {&#39;master&#39; (default), &#39;develop&#39;, &#39;v3.1b&#39;, ...}</span>
<span class="n">PROJECT_BRANCH</span> <span class="o">=</span> <span class="s1">&#39;master&#39;</span>
<span class="c1"># type = STRING, default = leave empty, help = if model branch is a TAG leave empty</span>
<span class="n">PROJECT_COMMIT</span> <span class="o">=</span>
</pre></div>
</div>
<p>Under <code class="docutils literal notranslate"><span class="pre">PROJECT_ORIGIN</span></code> the git username needs be replaced and under
<code class="docutils literal notranslate"><span class="pre">PROJECT_BRANCH</span></code> and <code class="docutils literal notranslate"><span class="pre">PROJECT_COMMIT</span></code> more fine grained settings can
be done. For our test simulation <code class="docutils literal notranslate"><span class="pre">master</span></code> is fine. All additional
configuration and script files used by autosubmit are located in the
REMO_MPI repository under the <code class="docutils literal notranslate"><span class="pre">autosubmit/conf</span></code> and
<code class="docutils literal notranslate"><span class="pre">autosubmit/jobs</span></code> directories, respectively. To include these files
automatically into the autosubmit structure, we have to make the
directories known to autosubmit by setting the following options:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">project_files</span><span class="p">]</span>
<span class="c1"># Where is PROJECT CONFIGURATION file location relative to project root path</span>
<span class="n">FILE_PROJECT_CONF</span> <span class="o">=</span> <span class="n">autosubmit</span><span class="o">/</span><span class="n">conf</span><span class="o">/</span><span class="n">proj_xxxx</span><span class="o">.</span><span class="n">conf</span>
<span class="c1"># Where is JOBS CONFIGURATION file location relative to project root path</span>
<span class="n">FILE_JOBS_CONF</span> <span class="o">=</span> <span class="n">autosubmit</span><span class="o">/</span><span class="n">conf</span><span class="o">/</span><span class="n">jobs_xxxx</span><span class="o">.</span><span class="n">conf</span>
<span class="c1"># Default job scripts type in the project. type = STRING, default = bash, supported = &#39;bash&#39;, &#39;python&#39; or &#39;r&#39;</span>
<span class="n">JOB_SCRIPTS_TYPE</span> <span class="o">=</span> <span class="s1">&#39;bash&#39;</span>
</pre></div>
</div>
<p>The paths are relative to the root directory of the git project. After
this, we can create the experiment by running</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">autosubmit</span> <span class="n">create</span> <span class="n">a001</span>
</pre></div>
</div>
<p>on the command line. This should download the REMO code into an
<code class="docutils literal notranslate"><span class="pre">a001/proj</span></code> directory, place additional configuration files into
<code class="docutils literal notranslate"><span class="pre">a001/conf</span></code>, and create a pdf showing the job flow of the experiment,
which most likely will look very basic. This is not the final experiment
flow and we will call <code class="docutils literal notranslate"><span class="pre">autosubmit</span> <span class="pre">create</span></code> later again to finalize the
experiment set-up.</p>
<p>In general, only the files located in the <code class="docutils literal notranslate"><span class="pre">conf</span></code> directory under the
autosubmit experiment root directory should be edited. The <code class="docutils literal notranslate"><span class="pre">create</span></code>
command should have created the main configuration file for the REMO
experiment, which is <code class="docutils literal notranslate"><span class="pre">proj_a001.conf</span></code>. In addition, <code class="docutils literal notranslate"><span class="pre">jobs_a001.conf</span></code>
should have been created which defines dependencies of the entire job
chain.</p>
<p>First, we will have a closr look at <code class="docutils literal notranslate"><span class="pre">proj_a001.conf</span></code>. It consists of
several sections where the most important ones for now are
<code class="docutils literal notranslate"><span class="pre">[BOUNDARY]</span></code> and <code class="docutils literal notranslate"><span class="pre">[REMO_RUN]</span></code>. The <code class="docutils literal notranslate"><span class="pre">[BOUNDARY]</span></code> sections contains
all important settings for the boundary data. In our example the section
should look like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Workflow relevant options</span>
<span class="p">[</span><span class="n">BOUNDARY</span><span class="p">]</span>
<span class="c1">## Usernumber of boundary data</span>
<span class="n">BOUND_USER</span> <span class="o">=</span> <span class="mi">058</span>
<span class="c1">## Experiment number of boundary data (if more than one member is calculated</span>
<span class="c1">## this is the base value)</span>
<span class="n">BOUND_EXP</span> <span class="o">=</span> <span class="mi">301</span>
<span class="c1">## Path to boundary data in archive</span>
<span class="n">BOUND_ARCH_PATH</span> <span class="o">=</span> <span class="o">/</span><span class="n">hpss</span><span class="o">/</span><span class="n">arch</span><span class="o">/</span><span class="n">ch0636</span><span class="o">/</span><span class="n">happi</span><span class="o">/</span><span class="n">nor</span><span class="o">-</span><span class="n">esm</span>
<span class="c1">## Style of experiment string: 1 = exp&lt;EXP&gt; | 2 = exp&lt;USER&gt;&lt;EXP&gt;</span>
<span class="n">BOUND_EXP_STR_STYLE</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1">## Boundary data is stored in monthly|yearly tar-files</span>
<span class="n">BOUND_ARCH_STYLE</span> <span class="o">=</span> <span class="n">yearly</span>
<span class="c1">## Keep the boundary data on disk: true|false</span>
<span class="n">KEEP_BOUND</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1">## Indicate if this will be using a warmstart. If false all WARM_... options</span>
<span class="c1">## can be omitted.</span>
<span class="n">WARMSTART</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1">## Usernumber of warmstart data</span>
<span class="n">WARM_USER</span> <span class="o">=</span> <span class="mi">001</span>
<span class="c1">## Experiment number of warmstart data</span>
<span class="n">WARM_EXP</span> <span class="o">=</span> <span class="mi">068</span>
<span class="c1">## Path to warmstart file</span>
<span class="n">WARM_PATH</span> <span class="o">=</span> <span class="o">/</span><span class="n">work</span><span class="o">/</span><span class="n">ch0636</span><span class="o">/</span><span class="n">m212075</span><span class="o">/</span><span class="n">warmstart</span>
</pre></div>
</div>
<p>Most of the settings should be self explaining, but one important aspect
is the handling of the warmstart. Here, the scripts expects a
restartfile (e.g., e001068f2000010100) with the given user and
experiment number and start date of the run. It is possible to just take
any restartfile (for the domain you are running on) and rename it
accordingly. Internally all relevant codes for a warmstart extracted
from the restartfile and put into the first boundary file (e.g.,
a058001a2000010100) overwriting any duplicate codes.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">[REMO_RUN]</span></code> section defines the configuration of the REMO run. In
our example it will read</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">REMO_RUN</span><span class="p">]</span>
<span class="c1">## Skip the first time step or not. True|False</span>
<span class="c1">## Needed for model runs that start at 06 instead of 00</span>
<span class="n">SKIP_FIRST</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1">## Will the model be compiled or not. True|False</span>
<span class="c1">## The following COMP_... options have to be set accordingly</span>
<span class="n">COMPILE</span> <span class="o">=</span> <span class="kc">True</span>
<span class="c1">## Filename of the tar-archive to be stored or retrieved without extension.</span>
<span class="n">COMP_NAME</span> <span class="o">=</span> <span class="n">test_remo_eur044</span>
<span class="c1">## Path where the project directory with compiled executable will be or is</span>
<span class="c1">## stored. Depending on the setting of COMPILE.</span>
<span class="n">COMP_ARCH</span> <span class="o">=</span> <span class="o">/</span><span class="n">work</span><span class="o">/</span><span class="n">ch0636</span><span class="o">/</span><span class="n">m212075</span><span class="o">/</span>
<span class="c1">## Comma seperated list of timesteps. First timestep is the default.</span>
<span class="c1">## The number of entries for DT_LIST should be equal to the number of</span>
<span class="c1">## retries for the simulation job!</span>
<span class="n">DT_LIST</span> <span class="o">=</span> <span class="mf">240.0</span><span class="p">,</span> <span class="mf">200.0</span><span class="p">,</span> <span class="mf">120.0</span>
<span class="c1">## Usernumber for REMO run</span>
<span class="n">REMO_USER</span> <span class="o">=</span> <span class="mi">058</span>
<span class="c1">## Experiment number for REMO run (if more than one member is calculated</span>
<span class="c1">## this is the base value)</span>
<span class="n">REMO_EXP</span> <span class="o">=</span> <span class="mi">301</span>
<span class="c1">## Working directory for data. Will be expanded by experiment string.</span>
<span class="n">WORK_DIR</span> <span class="o">=</span> <span class="o">/</span><span class="n">work</span><span class="o">/</span><span class="n">ch0636</span><span class="o">/</span><span class="n">m212075</span>
<span class="c1">## Path to store output data in archive</span>
<span class="n">REMO_ARCH_PATH</span> <span class="o">=</span> <span class="o">/</span><span class="n">hpss</span><span class="o">/</span><span class="n">arch</span><span class="o">/</span><span class="n">ch0636</span><span class="o">/</span><span class="n">happi</span><span class="o">/</span><span class="n">echam6</span>
<span class="c1">## Style of experiment string: 1 = exp&lt;EXP&gt; | 2 = exp&lt;USER&gt;&lt;EXP&gt;</span>
<span class="n">REMO_EXP_STR_STYLE</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1">## Data directory names for output on scratch: default|empty.</span>
<span class="c1">## If left empty the options PATH_A, PATH_E, PATH_F, PATH_M, PATH_N</span>
<span class="c1">## and PATH_T have to be set!</span>
<span class="n">DATA_DIRS</span> <span class="o">=</span> <span class="n">default</span>
<span class="c1">## Paths that need to be set, if DATA_DIRS is not default.</span>
<span class="n">PATH_A</span> <span class="o">=</span>
<span class="n">PATH_E</span> <span class="o">=</span>
<span class="n">PATH_F</span> <span class="o">=</span>
<span class="n">PATH_M</span> <span class="o">=</span>
<span class="n">PATH_N</span> <span class="o">=</span>
<span class="n">PATH_T</span> <span class="o">=</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">COMPILE</span></code> option will define if the model will be compiled or if
an existing executable will be used. If <code class="docutils literal notranslate"><span class="pre">COMPILE</span></code> is set to True the
entire REMO_MPI folder (including the executable) will be put into an
tar-archive using the name given by <code class="docutils literal notranslate"><span class="pre">COMP_NAME</span></code> and copied to
<code class="docutils literal notranslate"><span class="pre">COMP_ARCH</span></code>. In case <code class="docutils literal notranslate"><span class="pre">COMPILE</span></code> is set to False, the script expects
an tar-archive with the name given by <code class="docutils literal notranslate"><span class="pre">COMP_NAME</span></code> under path
<code class="docutils literal notranslate"><span class="pre">COMP_ARCH</span></code>. In this way one can reuse the same executable for a
series of experiments. As the time step is often the cause for model
crashes, one very useful setting is the option <code class="docutils literal notranslate"><span class="pre">DT_LIST</span></code> in the
<code class="docutils literal notranslate"><span class="pre">[REMO_RUN]</span></code> section of <code class="docutils literal notranslate"><span class="pre">proj_a001.conf</span></code>. This allows automatic
resubmission of the REMO job with different (preferably shorter) time
steps in the listed order. The first time step in the list is the
default for all jobs. Alternative time steps will only be used for the
current chunk (usual length is one month) and changed back to default
for the following. This mimics the standard procedure when dealing with
crashes with preceding warning messages such as <code class="docutils literal notranslate"><span class="pre">WARNING:</span> <span class="pre">VMAX=...</span></code>.
By default the folders <code class="docutils literal notranslate"><span class="pre">xa</span></code>, <code class="docutils literal notranslate"><span class="pre">xt</span></code>, <code class="docutils literal notranslate"><span class="pre">xe</span></code>, etc., are created in the
experiment folder. These can be changed but we will stick to the default
for now.</p>
<p>Some settings in <code class="docutils literal notranslate"><span class="pre">expdef_a001.conf</span></code> have important implications for
the behavior of settings in <code class="docutils literal notranslate"><span class="pre">proj_a001.conf</span></code> and the execution of the
job scripts. One of these important settings is the <code class="docutils literal notranslate"><span class="pre">MEMBERS</span></code> option
in the <code class="docutils literal notranslate"><span class="pre">[experiment]</span></code> section of <code class="docutils literal notranslate"><span class="pre">expdef_a001.conf</span></code>. If configured
for multiple members the <code class="docutils literal notranslate"><span class="pre">BOUND_EXP</span></code> and <code class="docutils literal notranslate"><span class="pre">REMO_EXP</span></code> values in
<code class="docutils literal notranslate"><span class="pre">proj_a001.conf</span></code> are interpreted as starting values for the
experiment. In addition, if the value of <code class="docutils literal notranslate"><span class="pre">MEMBERS</span></code> contains a
substring with the same name as one of the domain configuration files
(without extension) in <code class="docutils literal notranslate"><span class="pre">REMO_MPI/autosubmit/conf</span></code> (e.g., eur044 or
eur011), some default settings defined in the respective configuration
file are used in the NAMELIST. This offers some convenience when setting
up default experiments, because all important options for the NAMELIST
are already set, i.e. there is no need to add NAMELIST sections and
options to the <code class="docutils literal notranslate"><span class="pre">proj_a001.conf</span></code> file. The <code class="docutils literal notranslate"><span class="pre">proj_a001.conf</span></code> file
offers the opportunity to edit REMO NAMELIST setting individually
though, but this should be seen as advanced options and will not be
covered here.</p>
<p>Now we can run</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">autosubmit</span> <span class="n">create</span> <span class="n">a001</span>
</pre></div>
</div>
<p>again to properly configure the experiment. The experiment flow graph in
the pdf should confirm this by showing the complete tree now. Finally,
the experiment can be started by running</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">autosubmit</span> <span class="n">run</span> <span class="n">a001</span>
</pre></div>
</div>
<p>on the command line. It is usefull to start this a <code class="docutils literal notranslate"><span class="pre">screen</span></code> session in
order to be able to logout while the experiment is running. With running</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">autosubmit</span> <span class="n">monitor</span> <span class="n">a001</span>
</pre></div>
</div>
<p>on the command line you can create a pdf at any time, showing the
progress in the experiment flow graph. For more details on how to set up
an autosubmit experiment please refer to the autosubmit documentation.</p>
<div class="section" id="postprocessing-during-model-run">
<h4>Postprocessing during Model Run<a class="headerlink" href="#postprocessing-during-model-run" title="Permalink to this headline">¶</a></h4>
<p>Usually, after the end of the model run, the output data is
postprocessed in some way or the other. First of all, the output data is
copied from the <code class="docutils literal notranslate"><span class="pre">SCRATCH</span></code> partition and tarred under certain
conventions into a few number of tar-files and the postprocessing script
that is managed by the run script should take care of this. For details,
have a look at Section [sec:data_management]. However, there are two
python scripts which are used for further postprocessing and data
management.</p>
</div>
</div>
<div class="section" id="pressure-interpolation">
<h3>Pressure Interpolation<a class="headerlink" href="#pressure-interpolation" title="Permalink to this headline">¶</a></h3>
<p>The first script is called <code class="docutils literal notranslate"><span class="pre">pressure_interpolation.py</span></code> which is script
that manages the pressure interpolation of t-files and it is usually
started after one year of model time has been completed. The pressure
interpolation script is configured by a config file called
<code class="docutils literal notranslate"><span class="pre">config_durint.txt</span></code> which should be located in the current run script
directory. The python script is usually started by run script is a
complete year has been computed. The python script is managing the input
for and starts a FORTRAN program which then actually does the
computation. However, the python script is able to manage the data in
and output and creates the <code class="docutils literal notranslate"><span class="pre">INPUT</span></code> file for the FORTRAN pressure
interpolation program called <code class="docutils literal notranslate"><span class="pre">druint</span></code> (see Section [sec:druint]).</p>
</div>
<div class="section" id="archiving">
<h3>Archiving<a class="headerlink" href="#archiving" title="Permalink to this headline">¶</a></h3>
<div class="line-block">
<div class="line">There is another python script called <code class="docutils literal notranslate"><span class="pre">putscript.py</span></code> which manages
the packing and uploading of data to an HPSS tape archive. This script
is also called after a complete year of model time has been computed
so that all data for this year is stored under certain conventions in
the tape archive. The script accepts some command line inputs which
are usually managed by the run script.</div>
<div class="line">Both scripts, the <code class="docutils literal notranslate"><span class="pre">pressure_interpolation.py</span></code> and the
<code class="docutils literal notranslate"><span class="pre">putscript.py</span></code> are called by another batch script called
<code class="docutils literal notranslate"><span class="pre">put_$UE$EE_$Y.sh</span></code> that is submitted yearly by the main
postprocessing script. It is created from the template
<code class="docutils literal notranslate"><span class="pre">put_output_template.sh</span></code> in the <code class="docutils literal notranslate"><span class="pre">template</span></code> directory of the main
run script. If you have a look at the template, you can see that it
also is another batch script that should be run on a serial partition,
e.g., <code class="docutils literal notranslate"><span class="pre">shared</span></code> on MISTRAL.</div>
<div class="line">If you look closely in the header of the two scripts
<code class="docutils literal notranslate"><span class="pre">pressure_interpolation.py</span></code> and <code class="docutils literal notranslate"><span class="pre">putscript.py</span></code>, you can see that
these involve using the PyRemo tools, a library of python scripts
designed to work with REMO data (see Appendix [sec:pyremo]) You need
to install this libary and add it to you <code class="docutils literal notranslate"><span class="pre">PYTHONPATH</span></code> environment
variable. If you work on MISTRAL, you can use the common installation
of the GERICS project by adding this line to your profile (e.g.,
<code class="docutils literal notranslate"><span class="pre">.profile</span></code> or <code class="docutils literal notranslate"><span class="pre">.bashrc</span></code>):</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>export PYTHONPATH=/work/ch0636/sw/python/PyRemo-1.0.0:\${PYTHONPATH}
</pre></div>
</div>
</div>
</div>
<div class="section" id="model-spin-up">
<h2>Model Spin Up<a class="headerlink" href="#model-spin-up" title="Permalink to this headline">¶</a></h2>
<div class="line-block">
<div class="line">Usually, a special procedure is necessary for model initialisation.
The general philosophy behind the driving fields (a-files) is that
these files do not only contain the prognostic atmospheric parameters
for the lateral driving of REMO but also the surface/soil parameters
(see Table [tab:soil_fields]) that are necessary for model
initialisation (soil temperatures, soil wetness, snow cover, etc., see
Section [sec:creating_a-files]). Hence, all a-files can in principle
also be used for model initialisation.</div>
<div class="line">However, for the model run with REMO, the surface and soil fields
initialized with data from the forcing files might not be in an
equilibrium state with the atmosphere in the beginning of the model
run. Hence, the REMO model might run into a different equilibrium
state for the surface and soil fields than present in the forcing
files. The reason for this mainly lies in the increased resolution and
different surface and soil models incorporated in the regional
downscaling approach in REMO in contrast to the global model data from
which the forcing files are derived.</div>
<div class="line">Consequently, to avoid trends in the soil conditions, the soil needs a
<em>spin-up period</em> to reach a stable state. This period could range from
a few years to a few decades depending on the model domain. If a so
called <em>warm start</em> of the model run should be performed, the initial
conditions for the state of the surface and soil fields should be
updated with the corresponding fields after the spin-up period.</div>
</div>
<div class="line-block">
<div class="line-block">
<div class="line">| l | l | p7cm | Code &amp; Name &amp; Description</div>
</div>
<div class="line">84 &amp; QDBL &amp; specific humidity surface (land)</div>
<div class="line">140 &amp; WS &amp; soil wetness</div>
<div class="line">141 &amp; SN &amp; snow depth</div>
<div class="line">170 &amp; TD &amp; deep soil temperature</div>
<div class="line">183 &amp; TDCL &amp; soil temperature</div>
<div class="line">206 &amp; TSN &amp; snow temperature</div>
<div class="line">207 &amp; TD3 &amp; soil temperature</div>
<div class="line">208 &amp; TD4 &amp; soil temperature</div>
<div class="line">209 &amp; TD5 &amp; soil temperature</div>
<div class="line">194 &amp; WL &amp; skin reservoir content</div>
<div class="line">54 &amp; TSL &amp; surface temperature (land)</div>
<div class="line">55 &amp; TSW &amp; surface temperature (water)</div>
<div class="line">56 &amp; TSI &amp; surface temperature (ice)</div>
</div>
<p>You can carry out a <em>cold start</em> (slowly reacting surface/soil fields
are not in equilibrium yet and need about 5 years for spin up) then just
launch the model with the very first forcing file that was created for
00:00 o’clock of the very first day.</p>
<p>In case you want to carry out a warm start (surface/soil fields in
equilibrium), you need to choose a dataset for the surface and soil
fields that is in equilibrium with the atmospheric fields. This could
simply be the results of these fields of a cold start model run after
the spin-up period. However, a surface and soil dataset from a different
run on the same model domain and resolution should also provide
sufficient initial conditions for the surface and soil fields if they
reached an equilibrium state after the spin up period.</p>
<div class="section" id="replacing-surface-and-soil-data-in-a-forcing-file">
<h3>Replacing Surface and Soil Data in a Forcing File<a class="headerlink" href="#replacing-surface-and-soil-data-in-a-forcing-file" title="Permalink to this headline">¶</a></h3>
<p>Extracting and replacing certain variables or fields in a REMO in or
output file can be done in several ways. Here, we will show how to
extract the surface and soil fields from a REMO output file and replace
them in a forcing file using <code class="docutils literal notranslate"><span class="pre">cdo</span></code>. Typically, one would extract these
fields from a REMO t-file (which should contain all neccessary surface
and soil fields) after a certain spin-up period of 5-10 years. We assume
that the usual preprocessing during the model run create a tar archive
of t-files. First, we extract an output t-file of the same date as the
start date of the entire run but from a year in which the surface and
soil fields have reached equilibrium, e.g.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tar</span> <span class="o">-</span><span class="n">xvf</span> <span class="n">e056002t198901</span><span class="o">.</span><span class="n">tar</span> <span class="n">e056002t1989010100</span>
</pre></div>
</div>
<p>Second, we extract the surface and soil fields (see Table
[tab:soil_fields]) from the resulting file into an intermediate file
using the <code class="docutils literal notranslate"><span class="pre">cdo</span></code> operator <code class="docutils literal notranslate"><span class="pre">selcode</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cdo</span> <span class="n">selcode</span><span class="p">,</span><span class="mi">54</span><span class="p">,</span><span class="mi">55</span><span class="p">,</span><span class="mi">56</span><span class="p">,</span><span class="mi">206</span><span class="p">,</span><span class="mi">207</span><span class="p">,</span><span class="mi">208</span><span class="p">,</span><span class="mi">209</span><span class="p">,</span><span class="mi">170</span><span class="p">,</span><span class="mi">183</span><span class="p">,</span><span class="mi">84</span><span class="p">,</span><span class="mi">140</span><span class="p">,</span><span class="mi">194</span><span class="p">,</span><span class="mi">141</span> <span class="n">e056002t1990010100</span> <span class="n">warm_soil</span>
</pre></div>
</div>
<p>The file <code class="docutils literal notranslate"><span class="pre">warm_soil</span></code> now contains the surface and soil fields in
equilibrium. Now, we change the date of this file to the start date of
the run, e.g., 1st of January 1979 (10 year spin up period) using a
script called <code class="docutils literal notranslate"><span class="pre">ieg_setdate</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ieg8_setdate</span> <span class="n">warm_soil</span>
 <span class="n">IEG8_SETDATE</span>
 <span class="n">Enter</span> <span class="n">the</span> <span class="n">new</span> <span class="n">year</span><span class="p">:</span> <span class="n">YYYY</span>
<span class="mi">1979</span>
 <span class="n">Enter</span> <span class="n">the</span> <span class="n">new</span> <span class="n">month</span><span class="p">:</span> <span class="n">MM</span>
<span class="mi">01</span>
 <span class="n">Enter</span> <span class="n">the</span> <span class="n">new</span> <span class="n">day</span><span class="p">:</span> <span class="n">DD</span>
<span class="mi">01</span>
 <span class="n">Enter</span> <span class="n">the</span> <span class="n">new</span> <span class="n">hour</span><span class="p">:</span> <span class="n">HH</span>
<span class="mi">00</span>
</pre></div>
</div>
<p>which creates the file out8.ieg. In the next step, we extract the very
first forcing file from the tar archive using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tar</span> <span class="o">-</span><span class="n">xvf</span> <span class="n">a056002a197901</span><span class="o">.</span><span class="n">tar</span> <span class="n">a056002a1979010100</span>
</pre></div>
</div>
<p>and delete all surface and soil fields from this file using the <code class="docutils literal notranslate"><span class="pre">cdo</span></code>
operator <code class="docutils literal notranslate"><span class="pre">delcode</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cdo</span> <span class="n">delcode</span><span class="p">,</span><span class="mi">54</span><span class="p">,</span><span class="mi">55</span><span class="p">,</span><span class="mi">56</span><span class="p">,</span><span class="mi">206</span><span class="p">,</span><span class="mi">207</span><span class="p">,</span><span class="mi">208</span><span class="p">,</span><span class="mi">209</span><span class="p">,</span><span class="mi">170</span><span class="p">,</span><span class="mi">183</span><span class="p">,</span><span class="mi">84</span><span class="p">,</span><span class="mi">140</span><span class="p">,</span><span class="mi">194</span><span class="p">,</span><span class="mi">141</span> <span class="n">a056002a1979010100</span> <span class="n">a056002a1979010100</span>\<span class="n">_without</span>\<span class="n">_soil</span>
</pre></div>
</div>
<p>Finally, we have to concatenate the forcing file without surface and
soil fields (<code class="docutils literal notranslate"><span class="pre">a056002a1979010100_without_soil</span></code>) with the file
containing the spin up fields (<code class="docutils literal notranslate"><span class="pre">warm_soil</span></code>) using</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cat</span> <span class="n">a056002a1979010100_without_soil</span> <span class="n">out8</span><span class="o">.</span><span class="n">ieg</span> <span class="o">&gt;</span> <span class="n">a056002a1979010100</span>
</pre></div>
</div>
<p>This creates a new forcing file <code class="docutils literal notranslate"><span class="pre">a056002a1979010100</span></code> now containing
surface and soil fields in equilibrium state. We recommend to create a
new tar archive for the first month of the model run and replace the
first forcing file in this archive. This can be achieved, e.g., using</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cp</span> <span class="n">a056002a197901</span><span class="o">.</span><span class="n">tar</span> <span class="n">a056002a197901_warm_soil</span><span class="o">.</span><span class="n">tar</span>
<span class="n">tar</span> <span class="o">--</span><span class="n">delete</span> <span class="n">a056002a197901_warm_soil</span><span class="o">.</span><span class="n">tar</span> <span class="n">a056002a1979010100</span> <span class="c1"># delete old file</span>
<span class="n">tar</span> <span class="o">--</span><span class="n">append</span> <span class="n">a056002a197901_warm_soil</span><span class="o">.</span><span class="n">tar</span> <span class="n">a056002a1979010100</span> <span class="c1"># append new file</span>
</pre></div>
</div>
<div class="line-block">
<div class="line">Finally, the new tar archive should be uploaded to the HPSS archive if
available so that either a cold or a warm start is possible. Now the
model run can be restarted from the beginning with an equilibrium
state in the surface and soil fields.</div>
<div class="line">[sec:spinup]</div>
</div>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2019, Lars Buntemeyer.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>